{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bcb840b",
   "metadata": {},
   "source": [
    "# Image To Latex ML\n",
    "[IM2LATEX-100K dataset info](https://www.emergentmind.com/topics/im2latex-100k-dataset-ad016d42-2c17-4b9f-a959-bbe2d1d350d9)\n",
    "\n",
    "[im2markup](https://github.com/harvardnlp/im2markup/blob/master/README.md)\n",
    "\n",
    "Related Papers:\n",
    "\n",
    "[Image-to-Markup Generation with Coarse-to-Fine Attention (Harvard)](https://proceedings.mlr.press/v70/deng17a/deng17a.pdf)\n",
    "\n",
    "[Image To Latex (Stanford)](https://cs231n.stanford.edu/reports/2017/pdfs/815.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9ce4e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standard imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('dark_background')\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import io\n",
    "from PIL import Image\n",
    "# Standard Pytorch imports (note the aliases).\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as T\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "\n",
    "from pylatexenc.latexwalker import LatexWalker, LatexCharsNode, LatexMacroNode, LatexGroupNode\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0cbb7460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading ...\n",
      "First 5 records: \n",
      "                                              formula        filename  \\\n",
      "0  \\widetilde \\gamma _ { \\mathrm { h o p f } } \\s...  66667cee5b.png   \n",
      "1  ( { \\cal L } _ { a } g ) _ { i j } = 0 , \\ \\ \\...  1cbb05a562.png   \n",
      "2  S _ { s t a t } = 2 \\pi \\sqrt { N _ { 5 } ^ { ...  ed164cc822.png   \n",
      "3  \\hat { N } _ { 3 } = \\sum \\sp f _ { j = 1 } a ...  e265f9dc6b.png   \n",
      "4  \\, ^ { * } d \\, ^ { * } H = \\kappa \\, ^ { * } ...  242a58bc3a.png   \n",
      "\n",
      "                                         image.bytes image.path  \n",
      "0  b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...       None  \n",
      "1  b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...       None  \n",
      "2  b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...       None  \n",
      "3  b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...       None  \n",
      "4  b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\...       None  \n",
      "First 5 records formulas: \n",
      " 0    \\widetilde \\gamma _ { \\mathrm { h o p f } } \\s...\n",
      "1    ( { \\cal L } _ { a } g ) _ { i j } = 0 , \\ \\ \\...\n",
      "2    S _ { s t a t } = 2 \\pi \\sqrt { N _ { 5 } ^ { ...\n",
      "3    \\hat { N } _ { 3 } = \\sum \\sp f _ { j = 1 } a ...\n",
      "4    \\, ^ { * } d \\, ^ { * } H = \\kappa \\, ^ { * } ...\n",
      "Name: formula, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"loading ...\")\n",
    "\n",
    "base_url = \"hf://datasets/yuntian-deng/im2latex-100k/\"\n",
    "splits = {\n",
    "    'train': 'data/train-00000-of-00001-93885635ef7c6898.parquet', \n",
    "    'test': 'data/test-00000-of-00001-fce261550cd3f5db.parquet', \n",
    "    'val': 'data/val-00000-of-00001-3f88ebb0c1272ccf.parquet'\n",
    "}\n",
    "\n",
    "train_df = pd.read_parquet(base_url + splits[\"train\"])\n",
    "val_df   = pd.read_parquet(base_url + splits[\"val\"])\n",
    "test_df  = pd.read_parquet(base_url + splits[\"test\"])\n",
    "\n",
    "print(\"First 5 records: \\n\", train_df.head())\n",
    "print(\"First 5 records formulas: \\n\", train_df.head().formula)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b9d57c",
   "metadata": {},
   "source": [
    "## 1. Pre-processing\n",
    "- **Normalizzazione**: Poichè le formule hanno dimensioni variabili, è comune raggrupparle in \"bucket\" di risoluzione simile o ridimensionarle a una dimensione fissa (es. \\(480 X 160\\) o \\(640 X 160\\)) mantenendo l'aspect ratio. (sembrerebbe essere già fatta)\n",
    "- **Tokenizzazione**: La stringa LaTeX viene scomposta in token (es. \\frac, {, x, ^, 2, }). Viene aggiunto un vocabolario con token speciali come <sos> (inizio), <eos> (fine) e <pad> (riempimento)\n",
    "[Latex tokenizer](https://pylatexenc.readthedocs.io/en/latest/latexwalker/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddb4956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "formula originale: \\alpha _ { 1 } ^ { r } \\gamma _ { 1 } + \\dots + \\alpha _ { N } ^ { r } \\gamma _ { N } = 0 \\quad ( r = 1 , . . . , R ) \\; ,\n",
      "Token originali: ['<sos>', '\\\\widetilde', '_', '{', '\\\\mathrm', '}', '\\\\simeq', '\\\\sum', '_', '{', 'n', '>', '0', '}', '\\\\widetilde', '_', '{', 'n', '}', '{', '\\\\frac', '}', '<eos>']\n",
      "Indici numerici: [4, 5, 6, 7, 8, 9, 10, 11, 6, 7, 12, 13, 14, 9, 5, 6, 7, 12, 9, 7, 15, 9, 16]\n",
      "Dimensione del vocabolario: 442\n"
     ]
    }
   ],
   "source": [
    "class Vocabulary:\n",
    "    def __init__(self):\n",
    "        # Definiamo i token speciali con ID fissi\n",
    "        self.itos = {0: \"<pad>\", 1: \"<sos>\", 2: \"<eos>\", 3: \"<unk>\"}\n",
    "        self.stoi = {v: k for k, v in self.itos.items()}\n",
    "        self.threshold = 1 # Frequenza minima per includere un token\n",
    "\n",
    "    def build_vocabulary(self, sentence_list):\n",
    "        frequencies = Counter()\n",
    "        idx = 4\n",
    "        \n",
    "        for sentence in sentence_list:\n",
    "            for word in sentence:\n",
    "                frequencies[word] += 1\n",
    "                \n",
    "        for word, freq in frequencies.items():\n",
    "            if freq >= self.threshold:\n",
    "                self.stoi[word] = idx\n",
    "                self.itos[idx] = word\n",
    "                idx += 1\n",
    "\n",
    "    def numericalize(self, text):\n",
    "        return [self.stoi.get(token, self.stoi[\"<unk>\"]) for token in text]\n",
    "\n",
    "def parse_nodes(nodes):\n",
    "        flat_tokens = []\n",
    "        for node in nodes:\n",
    "            if node is None: continue\n",
    "\n",
    "            if node.isNodeType(LatexCharsNode):\n",
    "                # Caratteri semplici (a, b, =, +, ecc.)\n",
    "                # Li dividiamo ulteriormente per carattere singolo se necessario\n",
    "                for c in node.chars:\n",
    "                    if not c.isspace(): flat_tokens.append(c)\n",
    "                    \n",
    "            elif node.isNodeType(LatexMacroNode):\n",
    "                # Comandi tipo \\frac, \\alpha, \\cal\n",
    "                m_name = node.macroname\n",
    "                token = \"\\\\\" + m_name if m_name else \"\\\\\\\\\"\n",
    "                if token.strip() == \"\\\\\": continue\n",
    "                flat_tokens.append(token)\n",
    "                \n",
    "            elif node.isNodeType(LatexGroupNode):\n",
    "                # Gruppi tra { ... }, li apriamo ricorsivamente\n",
    "                flat_tokens.append(\"{\")\n",
    "                flat_tokens.extend(parse_nodes(node.nodelist))\n",
    "                flat_tokens.append(\"}\")\n",
    "        return flat_tokens\n",
    "\n",
    "\n",
    "def get_final_tokens(formula):\n",
    "    walker = LatexWalker(rf\"{formula}\")\n",
    "    try:\n",
    "        (nodes, pos, len_) = walker.get_latex_nodes()\n",
    "    except:\n",
    "        return []\n",
    "    \n",
    "    return [\"<sos>\"] + parse_nodes(nodes) + [\"<eos>\"]\n",
    "\n",
    "\n",
    "# 1. Istanzia e costruisci il vocabolario sui tuoi token\n",
    "tokenized = [get_final_tokens(formula) for formula in train_df.formula.values]\n",
    "vocab = Vocabulary()\n",
    "vocab.build_vocabulary(tokenized)\n",
    "\n",
    "# 2. Esempio di conversione della tua formula (record 1)\n",
    "example_indices = vocab.numericalize(tokenized[0])\n",
    "\n",
    "print(f\"formula originale: {test_df.formula.values[0]}\")\n",
    "print(f\"Token originali: {tokenized[0]}\")\n",
    "print(f\"Indici numerici: {example_indices}\")\n",
    "print(f\"Dimensione del vocabolario: {len(vocab.stoi)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd86140",
   "metadata": {},
   "source": [
    "### Aggiornare il Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d2c065",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Im2LatexDataset(Dataset):\n",
    "    def __init__(self, df, vocab, transform = None):\n",
    "        self.df = df\n",
    "        self.vocab = vocab\n",
    "        self.transform = transform\n",
    "        self.formulas= [get_final_tokens(f) for f in df.formula.values]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img_bytes = self.id.iloc[index]['images.bytes']\n",
    "        image = Image.open(io.BytesIO(img_bytes)).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        tokens = self.formulas[index]\n",
    "        numerical_indices = self.vocab.numericalize(tokens)\n",
    "        \n",
    "        return image, torch.tensor(numerical_indices)\n",
    "    \n",
    "\n",
    "# Trasformazioni: Resize fisso (importante!) e normalizzazione\n",
    "transform = T.Compose([\n",
    "    T.Resize((64, 320)), # Dimensioni immagini del dataset (Height, Width)\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.5,), (0.5,)) \n",
    "])\n",
    "\n",
    "dataset = Im2LatexDataset(test_df, vocab, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6fd907",
   "metadata": {},
   "source": [
    "### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7933b92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    images, sequences = zip(*batch)\n",
    "\n",
    "    #unire le immagini in unico tensore\n",
    "    images = torch.stack(images, dim=0)\n",
    "\n",
    "    #padding sequenze corte con 0 (<pad>)\n",
    "    sequences_padded = pad_sequence(sequences, batch_first=True, padding_value=0)\n",
    "\n",
    "    return images, sequences_padded\n",
    "\n",
    "dataLoader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f808ac",
   "metadata": {},
   "source": [
    "## 2. Feature Extraction (Encoder CNN)\n",
    "- **BakcBone**: ResNet-18 o una CNN custom (con circa 4-6 strati convoluzionali).\n",
    "- **Output**: Se l'input è \\(480\\times 160\\), la CNN produrrà una mappa di feature di circa \\(30\\times 10\\) con \\(512\\) canali. Ogni \"pixel\" di questa mappa rappresenta una piccola regione della formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72eb4e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CnnEncoder(nn.Module):\n",
    "    def __init__(self, d_model):\n",
    "        super().__init__()\n",
    "\n",
    "        # Una CNN semplice (stile ResNet ridotta)\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, 1, 1), nn.ReLU(), nn.MaxPool2d(2), # -> 32x160\n",
    "            nn.Conv2d(64, 128, 3, 1, 1), nn.ReLU(), nn.MaxPool2d(2), # -> 16x80\n",
    "            nn.Conv2d(128, 256, 3, 1, 1), nn.ReLU(), nn.MaxPool2d(2), # -> 8x40\n",
    "            nn.Conv2d(256, d_model, 3, 1, 1), nn.ReLU(), nn.MaxPool2d((2, 2)) # -> 4x20\n",
    "        )\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Output: [Batch, d_model, 4, 20]\n",
    "        features = self.conv(x)\n",
    "        # Lo \"appiattiamo\" per il Transformer: [Batch, 80, d_model]\n",
    "        # 80 è la lunghezza della sequenza visiva (4*20)\n",
    "        features = features.flatten(2).permute(0, 2, 1)\n",
    "        return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d688ac",
   "metadata": {},
   "source": [
    "## 3. Dalla griglia alla sequenza\n",
    "Il Transformer lavora su sequenze 1D, ma le formule sono intrinsecamente 2D.\n",
    "- **Flattening spaziale**: La mappa \\(30\\times 10\\) viene appiattita in una sequenza di \\(300\\) vettori.\n",
    "- **2D Positional Encoding**: Fondamentale per Im2Latex. Poiché una frazione ha elementi sopra e sotto, un encoding posizionale che mantenga coordinate \\((x,y)\\) aiuta il modello a capire la gerarchia verticale, non solo l'ordine destra-sinistra. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92d629e",
   "metadata": {},
   "source": [
    "## 4. Transformer Decoder (Generazione LaTeX)\n",
    "- **Self-Attention**: Il decoder analizza i token LaTeX già generati (es. se ha scritto \\begin{equation}, \"sa\" che dovrà chiuderlo).\n",
    "- **Cross-Attention**: Il decoder \"guarda\" i vettori estratti dalla CNN. Ad esempio, quando deve generare l'esponente, l'attenzione si sposterà sulla regione in alto a destra del simbolo di base nell'immagine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "11e57e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerDecoder(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, nhead, num_layers):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_encoding = nn.Parameter(torch.randn(1,1000, d_model)) # Positional enoding\n",
    "\n",
    "        decoder_layer = nn.TransformerDecoderLayer(d_model, nhead, batch_first=True)\n",
    "        self.transformer_decoder = nn.TransformerDecoder(decoder_layer, num_layers)\n",
    "\n",
    "        self.fc_out = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "    \n",
    "    def forward(self, tgt, memory, tgt_mask):\n",
    "        # tgt: token Latex [Batch, Seq_Len]\n",
    "        # memory: feature della CNN [Batch, 80, d_model]\n",
    "\n",
    "        tgt_emb = self.embedding(tgt) + self.pos_encoding[:, :tgt.size(1), :]\n",
    "\n",
    "        output = self.transformer_decoder(tgt_emb, memory, tgt_mask=tgt_mask)\n",
    "\n",
    "        return self.fc_out(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecdda22",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Im2LatexModel(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model=256, nhead=8, num_layers=4):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 1. ENCODER (CNN)\n",
    "        # Prende l'immagine [B, 3, 64, 320] -> restituisce feature [B, 80, d_model]\n",
    "        self.encoder_cnn = CnnEncoder(d_model) \n",
    "        \n",
    "        # 2. DECODER (Transformer)\n",
    "        # Prende i token LaTeX e le feature della CNN -> predice il prossimo token\n",
    "        self.decoder_transformer = TransformerDecoder(vocab_size, d_model, nhead, num_layers)\n",
    "\n",
    "    def forward(self, src_img, tgt_tokens):\n",
    "        # A. Estrazione feature visive (Memory)\n",
    "        # src_img shape: [Batch, 3, 64, 320]\n",
    "        memory = self.encoder_cnn(src_img) # Output: [Batch, 80, d_model]\n",
    "        \n",
    "        # B. Creazione maschera per il Decoder\n",
    "        # Impedisce di guardare i token futuri nella sequenza LaTeX\n",
    "        device = tgt_tokens.device\n",
    "        tgt_mask = nn.Transformer.generate_square_subsequent_mask(tgt_tokens.size(1)).to(device)\n",
    "        \n",
    "        # C. Generazione output tramite il Decoder\n",
    "        # tgt_tokens: [Batch, Seq_Len]\n",
    "        output = self.decoder_transformer(tgt_tokens, memory, tgt_mask)\n",
    "        \n",
    "        return output # [Batch, Seq_Len, Vocab_Size]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69741c67",
   "metadata": {},
   "source": [
    "## 5. Training e Inferenza\n",
    "- **Loss**: Si usa la Cross-Entropy calcolata su ogni token della sequenza LaTeX.\n",
    "- **Decoding**: In fase di test, non si sceglie solo il token più probabile (Greedy Search), ma si usa la Beam Search per esplorare più combinazioni e trovare la formula sintatticamente più corretta. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c014bb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Im2LatexModel(vocab_size=len(vocab.stoi)).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0) # Ignora il <pad>\n",
    "train_dataset = Im2LatexDataset(train_df, vocab, transform=transform)\n",
    "val_dataset   = Im2LatexDataset(val_df, vocab, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=32, \n",
    "    shuffle=True, \n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=2 # Opzionale: velocizza il caricamento\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=32, \n",
    "    shuffle=False, \n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "def generate_tgt_mask(sz, device):\n",
    "    mask = torch.triu(torch.ones(sz, sz, device=device) == 1)\n",
    "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask\n",
    "\n",
    "def train_epoch(model, dataloader, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for imgs, captions in dataloader:\n",
    "        imgs, captions = imgs.to(device), captions.to(device)\n",
    "        \n",
    "        # Prepariamo input e target: \n",
    "        # tgt_input: da <sos> a penultimo token\n",
    "        # tgt_expected: da secondo token a <eos>\n",
    "        tgt_input = captions[:, :-1]\n",
    "        tgt_expected = captions[:, 1:]\n",
    "        \n",
    "        tgt_mask = generate_tgt_mask(tgt_input.size(1), device)\n",
    "        \n",
    "        # Forward\n",
    "        preds = model(imgs, tgt_input, tgt_mask) # [B, Seq, Vocab]\n",
    "        \n",
    "        # Calcolo Loss (Flatten per CrossEntropy)\n",
    "        loss = criterion(preds.reshape(-1, preds.shape[-1]), tgt_expected.reshape(-1))\n",
    "        \n",
    "        # Backprop\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "def evaluate(model, dataloader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, captions in dataloader:\n",
    "            imgs, captions = imgs.to(device), captions.to(device)\n",
    "            tgt_input = captions[:, :-1]\n",
    "            tgt_expected = captions[:, 1:]\n",
    "            tgt_mask = generate_tgt_mask(tgt_input.size(1), device)\n",
    "            \n",
    "            preds = model(imgs, tgt_input, tgt_mask)\n",
    "            loss = criterion(preds.reshape(-1, preds.shape[-1]), tgt_expected.reshape(-1))\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "def predict(model, img, vocab, max_len=150):\n",
    "    model.eval()\n",
    "    device = img.device\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # 1. Estrai le feature dall'immagine (Memory)\n",
    "        memory = model.encoder(img) \n",
    "        \n",
    "        # 2. Inizia con il token <sos>\n",
    "        ys = torch.full((1, 1), vocab.stoi[\"<sos>\"], dtype=torch.long, device=device)\n",
    "        \n",
    "        for i in range(max_len):\n",
    "            # Crea la maschera per i token generati finora\n",
    "            tgt_mask = generate_tgt_mask(ys.size(1), device)\n",
    "            \n",
    "            # Predici il prossimo token\n",
    "            out = model(img, ys, tgt_mask)\n",
    "            prob = out[:, -1, :] # Prendi l'ultimo token predetto\n",
    "            _, next_word = torch.max(prob, dim=1) # Greedy: prendi il più probabile\n",
    "            \n",
    "            next_word = next_word.item()\n",
    "            ys = torch.cat([ys, torch.ones(1, 1, device=device, dtype=torch.long) * next_word], dim=1)\n",
    "            \n",
    "            # Se il modello predice <eos>, fermati\n",
    "            if next_word == vocab.stoi[\"<eos>\"]:\n",
    "                break\n",
    "        \n",
    "        # Converti gli indici in stringhe LaTeX\n",
    "        decoded_words = [vocab.itos[idx.item()] for idx in ys[0]]\n",
    "        return \" \".join(decoded_words)\n",
    "\n",
    "\n",
    "for epoch in range(10):\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, criterion)\n",
    "    val_loss = evaluate(model, val_loader, criterion)\n",
    "    print(f\"Epoch {epoch} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    example_img, example_tgt = next(iter(val_loader))\n",
    "    prediction = predict(model, example_img[0].unsqueeze(0).to(device), vocab)\n",
    "    print(f\"Real: {vocab.indices_to_string(example_tgt[0])}\")\n",
    "    print(f\"Pred: {prediction}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
