{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bcb840b",
   "metadata": {},
   "source": [
    "# Image To Latex ML\n",
    "[IM2LATEX-100K dataset info](https://www.emergentmind.com/topics/im2latex-100k-dataset-ad016d42-2c17-4b9f-a959-bbe2d1d350d9)\n",
    "\n",
    "[im2markup](https://github.com/harvardnlp/im2markup/blob/master/README.md)\n",
    "\n",
    "Related Papers:\n",
    "\n",
    "[Image-to-Markup Generation with Coarse-to-Fine Attention (Harvard)](https://proceedings.mlr.press/v70/deng17a/deng17a.pdf)\n",
    "\n",
    "[Image To Latex (Stanford)](https://cs231n.stanford.edu/reports/2017/pdfs/815.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9ce4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import sys\n",
    "print(sys.executable)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('dark_background')\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import io\n",
    "from PIL import Image\n",
    "# Standard Pytorch imports (note the aliases).\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as T\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "\n",
    "from pylatexenc.latexwalker import LatexWalker, LatexCharsNode, LatexMacroNode, LatexGroupNode\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbb7460",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"loading ...\")\n",
    "base_url = \"hf://datasets/yuntian-deng/im2latex-100k/\"\n",
    "splits = {\n",
    "    'train': 'data/train-00000-of-00001-93885635ef7c6898.parquet', \n",
    "    'test': 'data/test-00000-of-00001-fce261550cd3f5db.parquet', \n",
    "    'val': 'data/val-00000-of-00001-3f88ebb0c1272ccf.parquet'\n",
    "}\n",
    "\n",
    "train_df = pd.read_parquet(base_url + splits[\"train\"])\n",
    "val_df   = pd.read_parquet(base_url + splits[\"val\"])\n",
    "test_df  = pd.read_parquet(base_url + splits[\"test\"])\n",
    "print(train_df.size)\n",
    "\n",
    "print(\"First 5 records: \\n\", train_df.head())\n",
    "print(\"First 5 records formulas: \\n\", train_df.head().formula)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b9d57c",
   "metadata": {},
   "source": [
    "## 1. Pre-processing\n",
    "- **Normalizzazione**: Poichè le formule hanno dimensioni variabili, è comune raggrupparle in \"bucket\" di risoluzione simile o ridimensionarle a una dimensione fissa (es. \\(480 X 160\\) o \\(640 X 160\\)) mantenendo l'aspect ratio. (sembrerebbe essere già fatta)\n",
    "- **Tokenizzazione**: La stringa LaTeX viene scomposta in token (es. \\frac, {, x, ^, 2, }). Viene aggiunto un vocabolario con token speciali come <sos> (inizio), <eos> (fine) e <pad> (riempimento)\n",
    "[Latex tokenizer](https://pylatexenc.readthedocs.io/en/latest/latexwalker/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddb4956",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary:\n",
    "    def __init__(self):\n",
    "        # Token speciali con ID fissi\n",
    "        self.itos = {0: \"<pad>\", 1: \"<sos>\", 2: \"<eos>\", 3: \"<unk>\"}\n",
    "        self.stoi = {v: k for k, v in self.itos.items()}\n",
    "        self.threshold = 1  # Frequenza minima per includere un token\n",
    "\n",
    "    def build_vocabulary(self, sentence_list):\n",
    "        frequencies = Counter()\n",
    "        idx = 4  # Start dopo i token speciali\n",
    "\n",
    "        for sentence in sentence_list:\n",
    "            for word in sentence:\n",
    "                if word not in [\"<pad>\", \"<sos>\", \"<eos>\", \"<unk>\"]:\n",
    "                    frequencies[word] += 1\n",
    "\n",
    "        for word, freq in frequencies.items():\n",
    "            if freq >= self.threshold:\n",
    "                self.stoi[word] = idx\n",
    "                self.itos[idx] = word\n",
    "                idx += 1\n",
    "\n",
    "    def numericalize(self, text):\n",
    "        # Converte token in indici, usa <unk> se non trovato\n",
    "        return [self.stoi.get(token, self.stoi[\"<unk>\"]) for token in text]\n",
    "\n",
    "def parse_nodes(nodes):\n",
    "        flat_tokens = []\n",
    "        for node in nodes:\n",
    "            if node is None: continue\n",
    "\n",
    "            if node.isNodeType(LatexCharsNode):\n",
    "                # Caratteri semplici (a, b, =, +, ecc.)\n",
    "                # Li dividiamo ulteriormente per carattere singolo se necessario\n",
    "                for c in node.chars:\n",
    "                    if not c.isspace(): flat_tokens.append(c)\n",
    "                    \n",
    "            elif node.isNodeType(LatexMacroNode):\n",
    "                # Comandi tipo \\frac, \\alpha, \\cal\n",
    "                m_name = node.macroname\n",
    "                token = \"\\\\\" + m_name if m_name else \"\\\\\\\\\"\n",
    "                if token.strip() == \"\\\\\": continue\n",
    "                flat_tokens.append(token)\n",
    "                \n",
    "            elif node.isNodeType(LatexGroupNode):\n",
    "                # Gruppi tra { ... }, li apriamo ricorsivamente\n",
    "                flat_tokens.append(\"{\")\n",
    "                flat_tokens.extend(parse_nodes(node.nodelist))\n",
    "                flat_tokens.append(\"}\")\n",
    "        return flat_tokens\n",
    "\n",
    "\n",
    "def get_final_tokens(formula):\n",
    "    walker = LatexWalker(rf\"{formula}\")\n",
    "    try:\n",
    "        (nodes, pos, len_) = walker.get_latex_nodes()\n",
    "    except:\n",
    "        return []\n",
    "    \n",
    "    return [\"<sos>\"] + parse_nodes(nodes) + [\"<eos>\"]\n",
    "\n",
    "\n",
    "# 1. Istanzia e costruisci il vocabolario sui tuoi token\n",
    "# tokenized = [get_final_tokens(formula) for formula in train_df.formula.values]\n",
    "# vocab = Vocabulary()\n",
    "# vocab.build_vocabulary(tokenized)\n",
    "\n",
    "# # 2. Esempio di conversione della tua formula (record 1)\n",
    "# example_indices = vocab.numericalize(tokenized[0])\n",
    "\n",
    "# print(f\"formula originale: {test_df.formula.values[0]}\")\n",
    "# print(f\"Token originali: {tokenized[0]}\")\n",
    "# print(f\"Indici numerici: {example_indices}\")\n",
    "# print(f\"Dimensione del vocabolario: {len(vocab.stoi)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd86140",
   "metadata": {},
   "source": [
    "### Aggiornare il Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d2c065",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Im2LatexDataset(Dataset):\n",
    "    def __init__(self, df, vocab, tokenized_formulas, transform = None):\n",
    "        self.df = df\n",
    "        self.vocab = vocab\n",
    "        self.transform = transform\n",
    "        self.formulas= tokenized_formulas\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img_bytes = self.df.iloc[index]['image.bytes']\n",
    "        image = Image.open(io.BytesIO(img_bytes)).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        tokens = self.formulas[index]\n",
    "        tokens_idx = self.vocab.numericalize(tokens)\n",
    "        tokens_idx = torch.tensor(tokens_idx, dtype=torch.long)\n",
    "        \n",
    "        return image, tokens_idx\n",
    "    \n",
    "\n",
    "# Trasformazioni: Resize fisso (importante!) e normalizzazione\n",
    "transform = T.Compose([\n",
    "    T.Resize((64, 320)), # Dimensioni immagini del dataset (Height, Width)\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.5,), (0.5,)) \n",
    "])\n",
    "\n",
    "# dataset = Im2LatexDataset(test_df, vocab, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6fd907",
   "metadata": {},
   "source": [
    "### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7933b92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    imgs, captions = zip(*batch)\n",
    "    imgs = torch.stack(imgs)\n",
    "\n",
    "    lengths = [len(cap) for cap in captions]\n",
    "    max_len = max(lengths)\n",
    "\n",
    "    padded = torch.zeros(len(captions), max_len, dtype=torch.long)\n",
    "    for i, cap in enumerate(captions):\n",
    "        padded[i, :len(cap)] = cap\n",
    "\n",
    "    return imgs, padded\n",
    "\n",
    "\n",
    "# dataLoader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f808ac",
   "metadata": {},
   "source": [
    "## 2. Feature Extraction (Encoder CNN)\n",
    "- **BakcBone**: ResNet-18 o una CNN custom (con circa 4-6 strati convoluzionali).\n",
    "- **Output**: Se l'input è \\(480\\times 160\\), la CNN produrrà una mappa di feature di circa \\(30\\times 10\\) con \\(512\\) canali. Ogni \"pixel\" di questa mappa rappresenta una piccola regione della formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72eb4e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CnnEncoder(nn.Module):\n",
    "    def __init__(self, d_model):\n",
    "        super().__init__()\n",
    "\n",
    "        # Una CNN semplice (stile ResNet ridotta)\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, 1, 1), nn.ReLU(), nn.MaxPool2d(2), # -> 32x160\n",
    "            nn.Conv2d(64, 128, 3, 1, 1), nn.ReLU(), nn.MaxPool2d(2), # -> 16x80\n",
    "            nn.Conv2d(128, 256, 3, 1, 1), nn.ReLU(), nn.MaxPool2d(2), # -> 8x40\n",
    "            nn.Conv2d(256, d_model, 3, 1, 1), nn.ReLU(), nn.MaxPool2d((2, 2)) # -> 4x20\n",
    "        )\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Output: [Batch, d_model, 4, 20]\n",
    "        features = self.conv(x)\n",
    "        # Lo \"appiattiamo\" per il Transformer: [Batch, 80, d_model]\n",
    "        # 80 è la lunghezza della sequenza visiva (4*20)\n",
    "        features = features.flatten(2).permute(0, 2, 1)\n",
    "        return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d688ac",
   "metadata": {},
   "source": [
    "## 3. Dalla griglia alla sequenza\n",
    "Il Transformer lavora su sequenze 1D, ma le formule sono intrinsecamente 2D.\n",
    "- **Flattening spaziale**: La mappa \\(30\\times 10\\) viene appiattita in una sequenza di \\(300\\) vettori.\n",
    "- **2D Positional Encoding**: Fondamentale per Im2Latex. Poiché una frazione ha elementi sopra e sotto, un encoding posizionale che mantenga coordinate \\((x,y)\\) aiuta il modello a capire la gerarchia verticale, non solo l'ordine destra-sinistra. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92d629e",
   "metadata": {},
   "source": [
    "## 4. Transformer Decoder (Generazione LaTeX)\n",
    "- **Self-Attention**: Il decoder analizza i token LaTeX già generati (es. se ha scritto \\begin{equation}, \"sa\" che dovrà chiuderlo).\n",
    "- **Cross-Attention**: Il decoder \"guarda\" i vettori estratti dalla CNN. Ad esempio, quando deve generare l'esponente, l'attenzione si sposterà sulla regione in alto a destra del simbolo di base nell'immagine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e57e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerDecoder(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, nhead, num_layers):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_encoding = nn.Parameter(torch.randn(1,1000, d_model)) # Positional enoding\n",
    "\n",
    "        decoder_layer = nn.TransformerDecoderLayer(d_model, nhead, batch_first=True)\n",
    "        self.transformer_decoder = nn.TransformerDecoder(decoder_layer, num_layers)\n",
    "\n",
    "        self.fc_out = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "    \n",
    "    def forward(self, tgt, memory, tgt_mask):\n",
    "        # tgt: token Latex [Batch, Seq_Len]\n",
    "        # memory: feature della CNN [Batch, 80, d_model]\n",
    "\n",
    "        tgt_emb = self.embedding(tgt) + self.pos_encoding[:, :tgt.size(1), :]\n",
    "\n",
    "        output = self.transformer_decoder(tgt_emb, memory, tgt_mask=tgt_mask)\n",
    "\n",
    "        return self.fc_out(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecdda22",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Im2LatexModel(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model=256, nhead=8, num_layers=4):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 1. ENCODER (CNN)\n",
    "        # Prende l'immagine [B, 3, 64, 320] -> restituisce feature [B, 80, d_model]\n",
    "        self.encoder_cnn = CnnEncoder(d_model) \n",
    "        \n",
    "        # 2. DECODER (Transformer)\n",
    "        # Prende i token LaTeX e le feature della CNN -> predice il prossimo token\n",
    "        self.decoder_transformer = TransformerDecoder(vocab_size, d_model, nhead, num_layers)\n",
    "\n",
    "    def forward(self, src_img, tgt_tokens):\n",
    "        # A. Estrazione feature visive (Memory)\n",
    "        # src_img shape: [Batch, 3, 64, 320]\n",
    "        memory = self.encoder_cnn(src_img) # Output: [Batch, 80, d_model]\n",
    "        \n",
    "        # B. Creazione maschera per il Decoder\n",
    "        # Impedisce di guardare i token futuri nella sequenza LaTeX\n",
    "        device = tgt_tokens.device\n",
    "        tgt_mask = nn.Transformer.generate_square_subsequent_mask(tgt_tokens.size(1)).to(device)\n",
    "        \n",
    "        # C. Generazione output tramite il Decoder\n",
    "        # tgt_tokens: [Batch, Seq_Len]\n",
    "        output = self.decoder_transformer(tgt_tokens, memory, tgt_mask)\n",
    "        \n",
    "        return output # [Batch, Seq_Len, Vocab_Size]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69741c67",
   "metadata": {},
   "source": [
    "## 5. Training e Inferenza\n",
    "- **Loss**: Si usa la Cross-Entropy calcolata su ogni token della sequenza LaTeX.\n",
    "- **Decoding**: In fase di test, non si sceglie solo il token più probabile (Greedy Search), ma si usa la Beam Search per esplorare più combinazioni e trovare la formula sintatticamente più corretta. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c014bb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================\n",
    "# MINI DATASET DEBUG\n",
    "# =====================\n",
    "# train_df = train_df.sample(1000, random_state=2000)\n",
    "# val_df   = val_df.sample(100, random_state=2000)\n",
    "print(f\"TRAIN SIZE: {train_df.size}\")\n",
    "print(f\"TEST SIZE: {val_df.size}\")\n",
    "\n",
    "# 1. GENERAZIONE TOKEN (Senza Dataset per ora)\n",
    "print(\"Tokenizing training formulas...\")\n",
    "tokenized_train = [get_final_tokens(f) for f in train_df.formula.values]\n",
    "tokenized_val = [get_final_tokens(f) for f in val_df.formula.values]\n",
    "lengths = [len(f) for f in tokenized_train]\n",
    "print(f\"Lunghezza massima trovata nel Train: {max(lengths)}\")\n",
    "\n",
    "# 2. COSTRUZIONE VOCABOLARIO (Questo definisce la size finale)\n",
    "vocab = Vocabulary()\n",
    "vocab.build_vocabulary(tokenized_train)\n",
    "new_vocab_size = len(vocab.stoi)\n",
    "print(f\"Nuova dimensione vocabolario: {new_vocab_size}\") \n",
    "\n",
    "# 3. CREAZIONE DATASET E LOADER (Ora usano il vocab aggiornato)\n",
    "train_dataset = Im2LatexDataset(train_df, vocab, tokenized_train, transform=transform)\n",
    "val_dataset   = Im2LatexDataset(val_df, vocab, tokenized_val, transform=transform)\n",
    "\n",
    "# Importante: batch_size piccolo se sei su CPU o GPU limitata\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "# 4. SANITY CHECK (Ora deve passare per forza)\n",
    "max_found = 0\n",
    "for i, (imgs, caps) in enumerate(train_loader):\n",
    "    if i > 100: break # Controlla i primi 100 batch\n",
    "    if caps.max() >= new_vocab_size:\n",
    "        print(f\"!!! ERRORE AL BATCH {i} !!! Max idx: {caps.max()}\")\n",
    "        break\n",
    "    max_found = max(max_found, caps.max().item())\n",
    "print(f\"Controllo finito. Max index: {max_found} / Vocab Size: {new_vocab_size}\")\n",
    "\n",
    "\n",
    "# =====================\n",
    "# MODEL / DEVICE\n",
    "# =====================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "# 5. INIZIALIZZAZIONE MODELLO\n",
    "model = Im2LatexModel(vocab_size=new_vocab_size).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "\n",
    "\n",
    "def clean_formula(tensor, vocab):\n",
    "    \"\"\"\n",
    "    Decodifica un tensor di token in stringa LaTeX.\n",
    "    \"\"\"\n",
    "    if isinstance(tensor, torch.Tensor):\n",
    "        tokens = [vocab.itos[idx.item()] for idx in tensor]\n",
    "    else:\n",
    "        tokens = tensor\n",
    "    \n",
    "    # Rimuovi token speciali\n",
    "    tokens = [t for t in tokens if t not in (\"<pad>\", \"<sos>\", \"<eos>\")]\n",
    "    \n",
    "    # Unisci in stringa\n",
    "    formula = \" \".join(tokens)\n",
    "    \n",
    "    return formula.strip()\n",
    "\n",
    "# =====================\n",
    "# TRAIN & EVAL FUNCTIONS\n",
    "# =====================\n",
    "def train_epoch(model, dataloader, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for imgs, captions in dataloader:\n",
    "        imgs, captions = imgs.to(device), captions.to(device)\n",
    "        \n",
    "        # Prepariamo input e target: \n",
    "        # tgt_input: da <sos> a penultimo token\n",
    "        # tgt_expected: da secondo token a <eos>\n",
    "        tgt_input = captions[:, :-1]\n",
    "        tgt_expected = captions[:, 1:]\n",
    "        \n",
    "        # 2. Controllo di sicurezza sulle dimensioni\n",
    "        if tgt_input.size(1) == 0: continue\n",
    "\n",
    "        # Forward\n",
    "        preds = model(imgs, tgt_input) # [B, Seq, Vocab]\n",
    "        \n",
    "        # Calcolo Loss (Flatten per CrossEntropy)\n",
    "        loss = criterion(preds.reshape(-1, preds.shape[-1]), tgt_expected.reshape(-1))\n",
    "        \n",
    "        # Backprop\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip degli gradienti (evita esplosioni che possono causare errori CUDA)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "\n",
    "        if i % 100 == 0:\n",
    "           print(f\"Batch {i}/{len(dataloader)} - Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "def evaluate(model, dataloader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, captions in dataloader:\n",
    "            imgs, captions = imgs.to(device), captions.to(device)\n",
    "            tgt_input = captions[:, :-1]\n",
    "            tgt_expected = captions[:, 1:]\n",
    "            \n",
    "            preds = model(imgs, tgt_input)\n",
    "            loss = criterion(preds.reshape(-1, preds.shape[-1]), tgt_expected.reshape(-1))\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "def predict(model, img, vocab, max_len=150):\n",
    "    \"\"\"\n",
    "    Genera una sequenza di token LaTeX dall'immagine.\n",
    "\n",
    "    img: [1, 3, H, W] già su device\n",
    "    vocab: oggetto Vocabulary\n",
    "    max_len: lunghezza massima generata\n",
    "    return_tokens: se True restituisce lista di token, altrimenti stringa joinata\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    device = img.device\n",
    "    vocab_size = len(vocab.stoi)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # 1️⃣ Encode dell'immagine\n",
    "        memory = model.encoder_cnn(img)  # [B, Seq, d_model]\n",
    "\n",
    "        # 2️⃣ Inizializza sequenza con <sos>\n",
    "        ys = torch.full((1, 1), vocab.stoi[\"<sos>\"], dtype=torch.long, device=device)\n",
    "\n",
    "        for _ in range(max_len):\n",
    "            # Maschera triangolare\n",
    "            tgt_mask = torch.triu(\n",
    "                torch.ones(ys.size(1), ys.size(1), device=device) * float('-inf'),\n",
    "                diagonal=1\n",
    "            )\n",
    "\n",
    "            # 3️⃣ Decoder autoregressivo\n",
    "            out = model.decoder_transformer(ys, memory, tgt_mask=tgt_mask)  # [1, seq_len, vocab_size]\n",
    "\n",
    "            # 4️⃣ Greedy: prendi il token più probabile\n",
    "            next_word = out[:, -1, :].argmax(dim=-1).item()\n",
    "            next_word = max(0, min(next_word, vocab_size - 1))\n",
    "\n",
    "            # 5️⃣ Aggiungi alla sequenza\n",
    "            ys = torch.cat([ys, torch.tensor([[next_word]], device=device)], dim=1)\n",
    "\n",
    "            # 6️⃣ Stop se <eos>\n",
    "            if next_word == vocab.stoi[\"<eos>\"]:\n",
    "                break\n",
    "\n",
    "        # 7️⃣ Converti in token (lista di stringhe)\n",
    "        tokens = [vocab.itos[idx.item()] for idx in ys[0]]\n",
    "\n",
    "        return tokens\n",
    "\n",
    "\n",
    "# ===================== LOOP DI TRAIN =====================\n",
    "num_epochs = 12\n",
    "\n",
    "log_file = \"training_log.log\"\n",
    "\n",
    "with open(log_file, \"w\") as f:\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = train_epoch(model, train_loader, optimizer, criterion)\n",
    "        val_loss = evaluate(model, val_loader, criterion)\n",
    "\n",
    "        log_line = f\"Epoch {epoch} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\"\n",
    "        print(log_line)\n",
    "        f.write(log_line + \"\\n\")\n",
    "\n",
    "    # ===================== ESEMPIO FINALE =====================\n",
    "    example_img, example_tgt = next(iter(val_loader))\n",
    "    example_img = example_img[0].unsqueeze(0).to(device)\n",
    "\n",
    "    pred_tokens = predict(model, example_img, vocab)\n",
    "    prediction = clean_formula(pred_tokens, vocab)  # usa la funzione clean_formula\n",
    "    real_formula = clean_formula(example_tgt[0], vocab)\n",
    "    \n",
    "    final_example = f\"\\nEsempio finale:\\nReal: {real_formula}\\nPred: {prediction}\\n\"\n",
    "    print(final_example)\n",
    "    f.write(final_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7055a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_img, example_tgt = next(iter(val_loader))\n",
    "example_img = example_img[0].unsqueeze(0).to(device)\n",
    "\n",
    "pred_tokens = predict(model, example_img, vocab)\n",
    "prediction = clean_formula(pred_tokens, vocab)  # usa la funzione clean_formula\n",
    "\n",
    "real_formula = clean_formula(example_tgt[0], vocab)\n",
    "\n",
    "print(f\"\\nEsempio finale:\\nReal: {real_formula}\\nPred: {prediction}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cf71fa",
   "metadata": {},
   "source": [
    "### Beam Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac10be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_beam_search(model, img, vocab, k=3, max_len=150):\n",
    "    model.eval()\n",
    "    device = img.device\n",
    "    vocab_size = len(vocab.stoi)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # 1. Encode immagine\n",
    "        memory = model.encoder_cnn(img) \n",
    "\n",
    "        # 2. Inizializza il fascio: (punteggio_log, sequenza_indici)\n",
    "        # Partiamo con <sos> e punteggio 0\n",
    "        beams = [(0.0, [vocab.stoi[\"<sos>\"]])]\n",
    "\n",
    "        for _ in range(max_len):\n",
    "            new_beams = []\n",
    "            for score, seq in beams:\n",
    "                # Se la sequenza è già finita, la manteniamo così com'è\n",
    "                if seq[-1] == vocab.stoi[\"<eos>\"]:\n",
    "                    new_beams.append((score, seq))\n",
    "                    continue\n",
    "                \n",
    "                # Decoder forward per l'ultimo stato della sequenza\n",
    "                ys = torch.tensor([seq], device=device)\n",
    "                sz = ys.size(1)\n",
    "                tgt_mask = torch.triu(torch.ones(sz, sz, device=device) * float('-inf'), diagonal=1)\n",
    "                \n",
    "                out = model.decoder_transformer(ys, memory, tgt_mask=tgt_mask)\n",
    "                \n",
    "                # Prendi le log-probabilità dell'ultimo token\n",
    "                log_probs = torch.log_softmax(out[:, -1, :], dim=-1).squeeze(0)\n",
    "                \n",
    "                # Prendi i k migliori candidati per questo ramo\n",
    "                topk_probs, topk_idx = log_probs.topk(k)\n",
    "                \n",
    "                for i in range(k):\n",
    "                    new_beams.append((score + topk_probs[i].item(), seq + [topk_idx[i].item()]))\n",
    "            \n",
    "            # Seleziona i k migliori in assoluto tra tutti i rami espansi\n",
    "            beams = sorted(new_beams, key=lambda x: x[0], reverse=True)[:k]\n",
    "            \n",
    "            # Se tutti i rami hanno incontrato <eos>, abbiamo finito\n",
    "            if all(s[-1] == vocab.stoi[\"<eos>\"] for _, s in beams):\n",
    "                break\n",
    "        \n",
    "        # Restituisci la sequenza migliore (la prima della lista ordinata)\n",
    "        best_seq = beams[0][1]\n",
    "        return [vocab.itos[idx] for idx in best_seq]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220e59b1",
   "metadata": {},
   "source": [
    "### Test Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fbc209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Prepara i token del test set\n",
    "print(\"Tokenizing test set...\")\n",
    "tokenized_test = [get_final_tokens(f) for f in test_df.formula.values]\n",
    "test_dataset = Im2LatexDataset(test_df, vocab, tokenized_test, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# 2. Prendi un'immagine di esempio dal test set\n",
    "example_img, example_tgt = next(iter(test_loader))\n",
    "example_img = example_img.to(device)\n",
    "\n",
    "# 3. Confronto Greedy vs Beam\n",
    "print(\"--- CONFRONTO SUL TEST SET ---\")\n",
    "greedy_tokens = predict(model, example_img, vocab) # La tua vecchia funzione\n",
    "beam_tokens = predict_beam_search(model, example_img, vocab, k=3)\n",
    "\n",
    "print(f\"REAL:   {clean_formula(example_tgt[0], vocab)}\")\n",
    "print(f\"GREEDY: {clean_formula(greedy_tokens, vocab)}\")\n",
    "print(f\"BEAM:   {clean_formula(beam_tokens, vocab)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656ecf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from nltk.metrics import edit_distance\n",
    "\n",
    "def evaluate_official_metrics(model, dataloader, vocab, num_samples=100, k=3):\n",
    "    model.eval()\n",
    "    \n",
    "    em_count = 0\n",
    "    bleu_scores = []\n",
    "    edit_distances = []\n",
    "    \n",
    "    smoothie = SmoothingFunction().method4\n",
    "    print(f\"Valutazione ufficiale su {num_samples} campioni...\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (img, tgt) in enumerate(dataloader):\n",
    "            if i >= num_samples: break\n",
    "            \n",
    "            img = img.to(device)\n",
    "            \n",
    "            # Generazione con Beam Search (più vicina ai paper)\n",
    "            pred_tokens = predict_beam_search(model, img, vocab, k=k)\n",
    "            \n",
    "            # Pulizia stringhe\n",
    "            pred_str = clean_formula(pred_tokens, vocab)\n",
    "            real_str = clean_formula(tgt[0], vocab) # tgt è un batch di 1\n",
    "            \n",
    "            # 1. Exact Match (EM)\n",
    "            if pred_str.replace(\" \", \"\") == real_str.replace(\" \", \"\"):\n",
    "                em_count += 1\n",
    "            \n",
    "            # 2. BLEU Score\n",
    "            p_tokens = pred_str.split()\n",
    "            r_tokens = real_str.split()\n",
    "            b_score = sentence_bleu([r_tokens], p_tokens, smoothing_function=smoothie)\n",
    "            bleu_scores.append(b_score)\n",
    "            \n",
    "            # 3. Edit Distance (Text) - Normalizzata\n",
    "            max_len = max(len(pred_str), len(real_str))\n",
    "            if max_len > 0:\n",
    "                ed = edit_distance(pred_str, real_str)\n",
    "                # Molti paper riportano (1 - d/max_len)\n",
    "                norm_ed = 1 - (ed / max_len)\n",
    "            else:\n",
    "                norm_ed = 1.0\n",
    "            edit_distances.append(norm_ed)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(f\"REPORT FINALE SUL TEST SET\")\n",
    "    print(f\"Exact Match (EM):     {em_count/num_samples*100:.2f}%\")\n",
    "    print(f\"BLEU Score:           {np.mean(bleu_scores):.4f}\")\n",
    "    print(f\"Edit Distance (Text): {np.mean(edit_distances)*100:.2f}%\")\n",
    "    print(\"=\"*40)\n",
    "\n",
    "# Esegui il test finale\n",
    "evaluate_official_metrics(model, test_loader, vocab, num_samples=100)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "latex_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
